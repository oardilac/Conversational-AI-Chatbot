{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai\n",
    "!pip install gradio\n",
    "!pip install langchain\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "from gradio import Interface\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from chatbot.embeddings import generate_embeddings, search_embedding, load_embeddings_data\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI model\n",
    "llm_openai = OpenAI(model_name = \"text-davinci-003\", openai_api_key=openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ConversationBufferMemory and ConversationChain\n",
    "memory = ConversationBufferMemory()\n",
    "chatbot_chain = ConversationChain(llm=llm_openai, memory=memory, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sending prompt function\n",
    "def send_prompt(prompt, engine=\"text-davinci-003\", temp=0.5, max_tokens=100, top_p=1, frequency_penalty=0, presence_penalty=0):\n",
    "    response = openai.Completion.create(\n",
    "        engine=engine,\n",
    "        prompt=prompt,\n",
    "        temperature=temp,\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        presence_penalty=presence_penalty\n",
    "    )\n",
    "    return response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search function using embeddings\n",
    "def search_embedding(query, data, n_results=5):\n",
    "    query_embed = generate_embeddings(query, engine=\"text-embedding-ada-002\")\n",
    "    data[\"Similarity\"] = data['Embedding'].apply(lambda x: search_embedding(x, query_embed))\n",
    "    data = data.sort_values(\"Similarity\", ascending=False)\n",
    "    return data.iloc[:n_results][[\"text\", \"Similarity\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define chat function\n",
    "def chat(input_text):\n",
    "    response = chatbot_chain.predict(input = input_text)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Como me llamo?\n",
      "AI:  Tu nombre es [Nombre del usuario]. ¿Hay algo más en lo que pueda ayudarte?\n",
      "Human: hola\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Como me llamo?\n",
      "AI:  Tu nombre es [Nombre del usuario]. ¿Hay algo más en lo que pueda ayudarte?\n",
      "Human: hola\n",
      "AI:  Hola, ¿en qué puedo ayudarte?\n",
      "Human: Como me llamo?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Define main function\n",
    "def main():\n",
    "    # Load embeddings\n",
    "    embeddings_data = load_embeddings_data('data/processed/embeddings.csv')\n",
    "    \n",
    "    # Gradio interface\n",
    "    iface = Interface(\n",
    "        fn=chat, \n",
    "        inputs=\"text\", \n",
    "        outputs=\"text\", \n",
    "        examples=[\n",
    "            [\"What's the weather like today?\"],\n",
    "            [\"Tell me a joke.\"],\n",
    "            [\"Generate a poem about the sea.\"],\n",
    "        ]\n",
    "    )\n",
    "    iface.launch()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
